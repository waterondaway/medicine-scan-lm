{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/waterondaway/Laboratory/medicine-scan-lm/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import XLMRobertaForTokenClassification, XLMRobertaTokenizer\n",
    "import torch\n",
    "from torch.nn import functional as F \n",
    "model = XLMRobertaForTokenClassification.from_pretrained('../output/model/custom_tokenizer/checkpoint-75')\n",
    "tokenizer = XLMRobertaTokenizer.from_pretrained('../output/model/custom_tokenizer/checkpoint-75')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calling_model(text):\n",
    "    DRUG_NAME = \"\"\n",
    "    DOSAGE = \"\"\n",
    "    FORM = \"\"\n",
    "    DRUG_REG_NO = \"\"\n",
    "    MFG_DATE = \"\"\n",
    "    EXP_DATE = \"\"\n",
    "    WARNINGS = \"\"\n",
    "    INDICATIONS = \"\"\n",
    "    USAGE_INSTRUCTIONS = \"\"\n",
    "    OBJECT = \"\"\n",
    "    label2id = {\n",
    "        \"O\": 0,\n",
    "        \"B-DRUG_NAME\": 1, \"I-DRUG_NAME\": 2,\n",
    "        \"B-DOSAGE\": 3, \"I-DOSAGE\": 4,\n",
    "        \"B-FORM\": 5, \"I-FORM\": 6,\n",
    "        \"B-DRUG_REG_NO\": 7, \"I-DRUG_REG_NO\": 8,\n",
    "        \"B-MFG_DATE\": 9, \"I-MFG_DATE\": 10,\n",
    "        \"B-EXP_DATE\": 11, \"I-EXP_DATE\": 12,\n",
    "        \"B-WARNINGS\": 13, \"I-WARNINGS\": 14,\n",
    "        \"B-INDICATIONS\": 15, \"I-INDICATIONS\": 16,\n",
    "        \"B-USAGE_INSTRUCTIONS\": 17, \"I-USAGE_INSTRUCTIONS\": 18\n",
    "    }\n",
    "    id2label = {v: k for k, v in label2id.items()}\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "\n",
    "    print(tokens)\n",
    "\n",
    "    tokenized_input = tokenizer(tokens, is_split_into_words=True, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**tokenized_input)\n",
    "    logits = outputs.logits\n",
    "    print(logits)\n",
    "    probs = F.softmax(logits, dim=-1)\n",
    "    predictions = torch.argmax(probs, dim=-1)\n",
    "    for i, token in enumerate(tokens):\n",
    "        pred_label = id2label[predictions[0][i].item()]\n",
    "        confidence = probs[0][i][predictions[0][i]].item()*100\n",
    "        print(token, pred_label, confidence)\n",
    "        if(pred_label == \"O\"):\n",
    "            pred_label == \"O\"\n",
    "        else:\n",
    "            pred_label = pred_label.split('-')[1]\n",
    "        if(pred_label == \"DRUG_NAME\"):\n",
    "            DRUG_NAME += token\n",
    "        elif(pred_label == \"FORM\"):\n",
    "            FORM += token\n",
    "        elif(pred_label == \"DOSAGE\"):\n",
    "            DOSAGE += token\n",
    "        elif(pred_label == \"DRUG_REG_NO\"):\n",
    "            DRUG_REG_NO += token\n",
    "        elif(pred_label == \"MFG_DATE\"):\n",
    "            MFG_DATE += token\n",
    "        elif(pred_label == \"EXP_DATE\"):\n",
    "            EXP_DATE += token\n",
    "        elif(pred_label == \"WARNINGS\"):\n",
    "            WARNINGS += token\n",
    "        elif(pred_label == \"INDICATIONS\"):\n",
    "            INDICATIONS += token\n",
    "        elif(pred_label == \"USAGE_INSTRUCTIONS\"):\n",
    "            USAGE_INSTRUCTIONS += token\n",
    "        elif(pred_label == \"O\"):\n",
    "            OBJECT += token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calling_model(text):\n",
    "    DRUG_NAME = \"\"\n",
    "    OBJECT = \"\"\n",
    "    label2id = {\n",
    "        \"O\": 0,\n",
    "        \"B-DRUG_NAME\": 1, \"I-DRUG_NAME\": 2,\n",
    "    }\n",
    "    id2label = {v: k for k, v in label2id.items()}\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "\n",
    "    print(tokens)\n",
    "\n",
    "    tokenized_input = tokenizer(tokens, is_split_into_words=True, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**tokenized_input)\n",
    "    logits = outputs.logits\n",
    "    print(logits)\n",
    "    probs = F.softmax(logits, dim=-1)\n",
    "    predictions = torch.argmax(probs, dim=-1)\n",
    "    for i, token in enumerate(tokens):\n",
    "        pred_label = id2label[predictions[0][i].item()]\n",
    "        confidence = probs[0][i][predictions[0][i]].item()*100\n",
    "        print(token, pred_label, confidence)\n",
    "        if(pred_label == \"O\"):\n",
    "            pred_label == \"O\"\n",
    "        else:\n",
    "            pred_label = pred_label.split('-')[1]\n",
    "        if(pred_label == \"DRUG_NAME\"):\n",
    "            DRUG_NAME += token\n",
    "        elif(pred_label == \"FORM\"):\n",
    "            FORM += token\n",
    "        elif(pred_label == \"DOSAGE\"):\n",
    "            DOSAGE += token\n",
    "        elif(pred_label == \"DRUG_REG_NO\"):\n",
    "            DRUG_REG_NO += token\n",
    "        elif(pred_label == \"MFG_DATE\"):\n",
    "            MFG_DATE += token\n",
    "        elif(pred_label == \"EXP_DATE\"):\n",
    "            EXP_DATE += token\n",
    "        elif(pred_label == \"WARNINGS\"):\n",
    "            WARNINGS += token\n",
    "        elif(pred_label == \"INDICATIONS\"):\n",
    "            INDICATIONS += token\n",
    "        elif(pred_label == \"USAGE_INSTRUCTIONS\"):\n",
    "            USAGE_INSTRUCTIONS += token\n",
    "        elif(pred_label == \"O\"):\n",
    "            OBJECT += token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ไอบูโพรเฟน']\n",
      "tensor([[[ 1.9579e+00, -2.8307e-01, -1.2438e+00],\n",
      "         [ 3.2329e+00, -2.9579e-02, -3.0413e+00],\n",
      "         [ 4.3937e+00, -3.1662e-03, -4.8254e+00]]])\n",
      "ไอบูโพรเฟน O 87.18053698539734\n"
     ]
    }
   ],
   "source": [
    "calling_model(\"ไอบูโพรเฟน\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ไดอะซีแพม']\n",
      "tensor([[[ 1.9508e+00, -2.8459e-01, -1.2348e+00],\n",
      "         [ 3.2455e+00, -2.9956e-02, -3.0624e+00],\n",
      "         [ 4.3922e+00, -1.0591e-03, -4.8349e+00]]])\n",
      "ไดอะซีแพม O 87.08502650260925\n"
     ]
    }
   ],
   "source": [
    "calling_model(\"ไดอะซีแพม\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
